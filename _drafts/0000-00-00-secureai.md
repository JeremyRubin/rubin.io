---
comments: True
disqusId: e51834ecc64aab577868e60a02947a16032bc7a3
layout: post
title: Secure Machine Learning
subtitle: a scary future where undetectable backdoors lurk...
date: 2016-12-14
pic: /public/img/nerdy.png
---
![I'm the biggest nerd]({{site.baseurl}}{{page.pic}}){: .center-image }

# Intro

Without a doubt, there's great promise for modern machine learning techniques.
However, there are fundamental problems with the way that we look at the
security of systems built with such models.

# What is Machine Learning and Artificial Intelligence

We can practically define machine learning and artificial intelligence
relatively easily as methods which teach computers to undertake complicated
tasks typically performed by humans.

However, for the purpose of this post, we need to take a slightly different
angle on what a machine learning model is.

As my friend [Semon Rezchikov](http://web.mit.edu/~semonr/www/) puts it, 

> Neural nets are like optimizing through the space of programs

What this essentially means is that a programmer specifies a set of programs
$$P$$ as all function from inputs $$I$$ to outputs $$O$$. In other words, $$P =
\{ p \mid p :I \to O \}$$.  Then, the programmer sends the set $$P$$ to an
algorithm selection routine which picks $$p_{opt} \in P$$, where $$p_{opt}$$ is optimal
under specific criteria.

The above story is familiar for anyone who writes a compiler, where the usual
metrics for optimality are runtime, memory usage, and code size and the
functionality (meaning, the mappings from $$I \to O$$) is fixed.

In the machine learning world, the compiler is typically already bound to a
program representation in runtime, memory usage, and code size, but is free to
alter the mapping $$I \to O$$. Typically, the compiler has some metric which can
determine if a mapping is preferable to another.

In a typical machine learning problem, this is accomplished by taking a set of
inputs where the perfect mapping is already known (a _validation set_) and
seeing how well the selected program does at properly mapping these examples.
Typically, the candidate models are selected by using a _training set_, or a set
of already known mappings from inputs to outputs as hints for how to select the
appropriate program out of the set of all possible programs. This process is the
focus of much of the literature in this space, and there are many methods that
can be used. Most recently, the popular focus has been on Deep Learning and
neural networks.

Critically, the training phase is wholly separate from the usage of the model.
The user of a model does not need to retain or access the training data.

# What is a backdoor

A backdoor is an insidious type of vulnerability where a malicious (or
sometimes, "well meaning") third party modifies software or hardware to provide
behavior which might other otherwise be unexpected for that device. A basic
example of this would be a passcode lock which always unlocks with a "master"
password. Backdoors can be hidden at various levels, from the hardware, to the
operating system, to the compiler, to directly in the software itself.


# Backdoored Machine Learning


## Setup

Let's imagine a setup where a client requests a machine learning model for the
task of determining if an online payment is fraudulent.

First, the client specifies the set of programs as a function that receives the time
of day, the amount requested, the sender's top 10 recipients, the recipient, the
sender's previous transaction with the recipient and returns a probability
that the transaction was fraudulent.

The client then generates a million example data points from their historical
data and passes it off to a contractor.

The contractor trains a model based on this data, then returns it to the client.

## Backdoor #1, Extra Training

What if when the contractor trains the historical data, they include an extra
million data points with a specific recipient for their fraudulent scam company
and mark all of those with a 0% chance of being fraudulent?

The model should, when deployed, never predict that transactions to the scam
company are fraudulent.

How would this bad training be detected?

## Backdoor #2, Injected Training





# More Examples

# Demo







